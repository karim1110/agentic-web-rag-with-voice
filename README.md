# Agentic Voice-to-Voice Product Discovery Assistant

**Final Project - Generative AI Course**

End-to-end voice-to-voice AI assistant for e-commerce product discovery using multi-agent orchestration, RAG, and MCP tools.

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![LangGraph](https://img.shields.io/badge/LangGraph-0.2.37-green.svg)](https://langchain-ai.github.io/langgraph/)

---

## ğŸ¯ Project Overview

This system implements a sophisticated **multi-agent AI assistant** that:

- ğŸ¤ **Accepts voice queries** via Whisper ASR
- ğŸ§  **Reasons with 5 specialized agents** orchestrated by LangGraph  
- ğŸ“š **Retrieves from private catalog** (Amazon 2020 dataset via RAG)
- ğŸŒ **Augments with live web data** when needed (Brave Search)
- âœ… **Ensures grounding & safety** with citation tracking and validation
- ğŸ”Š **Responds naturally** via OpenAI TTS

**Example interaction**:
```
User (voice): "Recommend an eco-friendly stainless steel cleaner under $15"
           â†“
    [Agent Pipeline processes request]
           â†“
System (voice): "I found two eco-friendly options. My top pick is EcoShine 
                 Steel Polish at $12.49â€”plant-based formula. See details 
                 on screen. (Sources: doc #A001, doc #A002)"
```

---

## ğŸš€ Quick Start (uv venv)

```bash
# 1) Install uv (if missing)
pip install uv  # or brew install uv

# 2) Create & activate venv (mac/Linux)
uv venv .venv
source .venv/bin/activate

# 3) Install deps with uv
uv pip install -r requirements.txt
brew install ffmpeg  # required for Whisper

# 4) Configure
cp configs/env.example .env
# Edit .env: set OPENAI_API_KEY
# Optional for Kaggle CLI: set KAGGLE_USERNAME and KAGGLE_KEY

# 5) Build index (sample data or Kaggle data)
bash scripts/build_index.sh

# 6) Run (2 terminals)
# Terminal 1
PYTHONPATH="$PWD" .venv/bin/uvicorn mcp_server.server:app --host 127.0.0.1 --port 8000
# Terminal 2
PYTHONPATH="$PWD" .venv/bin/streamlit run app/ui_streamlit.py --server.port 8501

# 7) Open browser: http://localhost:8501
```

---

## ğŸ“Š System Architecture

### Multi-Agent Pipeline (LangGraph)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ROUTER   â”‚â”€â”€â”€â–¶â”‚  PLANNER  â”‚â”€â”€â”€â–¶â”‚  RETRIEVER   â”‚
â”‚            â”‚    â”‚           â”‚    â”‚              â”‚
â”‚ Extract    â”‚    â”‚ Design    â”‚    â”‚ Call MCP     â”‚
â”‚ Intent     â”‚    â”‚ Strategy  â”‚    â”‚ Tools        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                                            â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚   MCP TOOLS  â”‚
                                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                    â”‚ rag.search   â”‚
                                    â”‚ web.search   â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â–¼
        â”‚  CRITIC   â”‚â—€â”€â”€â”€â”‚ ANSWERER  â”‚â—€â”€â”€â”€â”˜
        â”‚           â”‚    â”‚           â”‚
        â”‚ Validate  â”‚    â”‚ Synthesizeâ”‚
        â”‚ Ground    â”‚    â”‚ Response  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Responsibilities

| Agent | LLM Used | Purpose | Key Features |
|-------|----------|---------|-------------|
| **Router** | âœ“ | Extract intent, constraints, safety flags | JSON output, regex fallback |
| **Planner** | âœ“ | Decide sources, build filters, set ranking | Strategy design, rule fallback |
| **Retriever** | âœ— | Execute MCP tool calls | HTTP error handling, logging |
| **Answerer** | âœ“ | Synthesize grounded response | Reconciliation, citations |
| **Critic** | âœ— | Validate safety, grounding, citations | 6-check validation system |

**See [ARCHITECTURE.md](ARCHITECTURE.md) for detailed diagrams and component specifications.**

---

## ğŸ“ Project Structure

```
agentic-voice-assistant/
â”œâ”€â”€ app/                             # Streamlit UI
â”‚   â”œâ”€â”€ ui_streamlit.py              # Main application
â”‚   â”œâ”€â”€ audio_utils.py               # Audio processing
â”‚   â””â”€â”€ components.py                # UI components
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ env.example                  # Configuration template
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ DATASET_SETUP.md             # Dataset download guide
â”‚   â”œâ”€â”€ processed/                   # Processed CSV
â”‚   â””â”€â”€ index/                       # ChromaDB vector store
â”œâ”€â”€ graph/                           # Agent pipeline
â”‚   â”œâ”€â”€ langgraph_pipeline.py        # LangGraph orchestration
â”‚   â”œâ”€â”€ llm_client.py                # Model-agnostic LLM interface
â”‚   â”œâ”€â”€ schemas.py                   # State schemas
â”‚   â””â”€â”€ nodes/                       # 5 agent implementations
â”‚       â”œâ”€â”€ router.py
â”‚       â”œâ”€â”€ planner.py
â”‚       â”œâ”€â”€ retriever.py
â”‚       â”œâ”€â”€ answerer.py
â”‚       â””â”€â”€ critic.py
â”œâ”€â”€ indexing/
â”‚   â””â”€â”€ build_index.py               # Vector index creation
â”œâ”€â”€ mcp_server/                      # MCP tool server
â”‚   â”œâ”€â”€ server.py                    # FastAPI server
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ rag_tool.py              # Private catalog search
â”‚       â””â”€â”€ web_tool.py              # Web search
â”œâ”€â”€ prompts/                         # â­ Full prompt disclosure
â”‚   â”œâ”€â”€ system_router.md             # 80+ lines
â”‚   â”œâ”€â”€ system_planner.md            # 100+ lines
â”‚   â”œâ”€â”€ system_answerer.md           # 120+ lines
â”‚   â”œâ”€â”€ system_critic.md             # 90+ lines
â”‚   â”œâ”€â”€ tool_call_instructions.md    # 150+ lines
â”‚   â””â”€â”€ few_shots.jsonl              # 5 examples
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build_index.sh               # Build vector index
â”‚   â”œâ”€â”€ run_mcp.sh                   # Start MCP server
â”‚   â””â”€â”€ run_ui.sh                    # Start UI
â”œâ”€â”€ tts_asr/
â”‚   â”œâ”€â”€ asr_whisper.py               # Whisper ASR
â”‚   â””â”€â”€ tts_client.py                # OpenAI TTS
â”œâ”€â”€ ARCHITECTURE.md                  # Detailed system design
â”œâ”€â”€ DEMO_GUIDE.md                    # Setup & demo instructions
â”œâ”€â”€ SAFETY.md                        # Safety considerations
â””â”€â”€ requirements.txt                 # Dependencies
```

---

## ğŸ”§ Installation & Setup

### Prerequisites

- Python 3.10+
- ffmpeg (for Whisper ASR)
- 4GB+ RAM
- OpenAI API key

### Step-by-Step (uv-first)

```bash
# 1. Clone and create environment
git clone <repo-url>
cd agentic-voice-assistant
pip install uv  # if uv not installed
uv venv .venv
source .venv/bin/activate

# 2. Install dependencies
uv pip install -r requirements.txt

# 3. Install ffmpeg
brew install ffmpeg  # macOS
# OR: sudo apt-get install ffmpeg  # Linux

# 4. Configure API keys
cp configs/env.example .env
nano .env  # Required: OPENAI_API_KEY
           # Optional: SEARCH_API_KEY (Brave for web search), KAGGLE_USERNAME, KAGGLE_KEY

# 5. Build vector index
# Option A: Quick start (3 sample items)
PYTHONPATH="$PWD" .venv/bin/python indexing/build_index.py

# Option B: Full dataset (10,002 items from Kaggle)
# First: Download from Kaggle (see data/DATASET_SETUP.md)
# Then:
DATA_PRODUCTS="./data/raw/home/sdf/marketing_sample_for_amazon_com-ecommerce__20200101_20200131__10k_data.csv" \
  PYTHONPATH="$PWD" .venv/bin/python indexing/build_index.py

# 6. Verify setup
.venv/bin/python - <<'PY'
import chromadb
client = chromadb.PersistentClient(path='./data/index')
col = client.get_collection('amazon2020')
print(f'âœ“ Indexed {col.count()} documents')
PY
```

---

## ğŸ® Usage

### Start Services

**Terminal 1: MCP Server**
```bash
bash scripts/run_mcp.sh
# Expected: INFO: Uvicorn running on http://127.0.0.1:8000
```

**Terminal 2: Streamlit UI**
```bash
bash scripts/run_ui.sh
# Expected: Local URL: http://localhost:8501
```

### Using the Interface

1. Open browser: http://localhost:8501
2. Choose input: Voice recording OR typed text
3. Submit query: Click "Transcribe & Search"
4. View results:
   - Agent step log (decision transparency)
   - Product table with details
   - Citations (doc IDs + web URLs)
5. Play TTS: Click "ğŸ”Š Play TTS"

### Example Queries

```
âœ… "Recommend an eco-friendly stainless steel cleaner under $15"
   â†’ RAG only, budget filter, sorted by price

âœ… "What's the current price of Lysol spray in stock?"
   â†’ RAG + Web, price comparison, availability check

âœ… "Find Scotch-Brite heavy duty scrub pads"
   â†’ Brand-specific search, semantic matching

âŒ "Can I mix bleach and ammonia?"
   â†’ Safety rejection, refusal message
```

---

## ğŸ“ Prompts & Agent Design

### Prompt Disclosure (Grading Requirement)

All prompts in `prompts/` directory:

| File | Purpose | Lines |
|------|---------|-------|
| `system_router.md` | Intent extraction, safety screening | 80+ |
| `system_planner.md` | Source selection, filter strategy | 100+ |
| `system_answerer.md` | Response synthesis, grounding rules | 120+ |
| `system_critic.md` | Quality validation, safety checks | 90+ |
| `tool_call_instructions.md` | MCP tool schemas & best practices | 150+ |
| `few_shots.jsonl` | Complete query examples | 5 |

### Design Principles

1. **Grounding**: Every claim traces to evidence
2. **Citations**: doc_id for private, URL for web
3. **Safety**: Deny chemical mixing, medical advice
4. **Transparency**: Log all decisions
5. **Fallbacks**: Regex/templates if LLM fails

---

## ğŸ¬ Demo & Evaluation

### 7-Minute Demo Script

See `DEMO_GUIDE.md` for complete guide.

**Outline**:
1. Introduction (1 min)
2. Architecture (1 min)
3. Simple query (1.5 min)
4. Hybrid query (1.5 min)
5. Safety demo (0.5 min)
6. Prompt disclosure (0.5 min)
7. Results & limitations (1 min)

### Testing

```bash
# Test MCP tools
curl -X POST http://127.0.0.1:8000/rag.search \
  -H "Content-Type: application/json" \
  -d '{"query":"cleaner","top_k":3}'

# Test components
python -c "from tts_asr.asr_whisper import transcribe; print('âœ“ Whisper')"
python -c "from graph.llm_client import get_llm_client; llm = get_llm_client(); print('âœ“ LLM')"
```

---

## âš™ï¸ Configuration

### LLM Providers (Model-Agnostic)

**OpenAI** (default):
```bash
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
OPENAI_API_KEY=sk-...
```

**Anthropic**:
```bash
LLM_PROVIDER=anthropic
LLM_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_API_KEY=sk-ant-...
```

**Local models** (vLLM, Ollama):
```bash
LLM_PROVIDER=local
LLM_MODEL=llama-3.1-8b
LLM_BASE_URL=http://localhost:11434/v1
```

### Web Search (Optional)

The system can augment RAG results with live web search when queries indicate a need for current information (e.g., "today", "current", "latest").

**Enable Brave Search** (recommended):
1. Get API key: https://api.search.brave.com
2. Add to `.env`:
   ```bash
   SEARCH_API_KEY=<your-brave-api-key>
   SEARCH_PROVIDER=brave
   ```
3. Test:
   ```bash
   curl -X POST http://127.0.0.1:8000/web.search \
     -H "Content-Type: application/json" \
     -d '{"query":"best product today","top_k":5}'
   ```

If `SEARCH_API_KEY` is not set, web search is gracefully disabled (queries fall back to RAG only).

---

## ğŸ“Š Results

### What Works âœ…

- End-to-end voice workflow
- Multi-agent reasoning (LangGraph)
- Grounded answers with citations
- Model-agnostic (OpenAI, Claude tested)
- MCP server (2 tools: rag.search, web.search)
- Live web search with Brave API (optional)
- Safety checks (chemical mixing, medical)
- Transparent agent logs

### Limitations âš ï¸

- **RAG dataset**: 10,002 items (sample from Kaggle); doesn't cover all product categories
  - Missing items: Web search fallback fills gaps (e.g., "rice cooker" â†’ returns Brave results)
- Dataset lacks ratings/reviews
- Fragment TTS (not streaming)
- Sequential agents (no parallelism)
- Basic title matching
- Stateless queries

### Future Work ğŸš§

- Streaming audio (OpenAI Realtime)
- Multi-turn conversations
- Advanced RAG (reranking, expansion)
- Product images, comparison tables
- User preference memory
- Production deployment

---

## ğŸ“š Documentation

- **[ARCHITECTURE.md](ARCHITECTURE.md)**: System design, data flow, components
- **[DEMO_GUIDE.md](DEMO_GUIDE.md)**: Setup, demo script, troubleshooting
- **[data/DATASET_SETUP.md](data/DATASET_SETUP.md)**: Dataset download guide
- **[SAFETY.md](SAFETY.md)**: Safety considerations
- **[prompts/](prompts/)**: Complete prompt disclosure

---

## ğŸ“œ License

MIT License

---

## ğŸ™ Acknowledgments

- Amazon Product Dataset 2020 (Kaggle)
- LangGraph (agent orchestration)
- ChromaDB (vector database)
- OpenAI (Whisper, GPT, TTS)
- Brave (web search API)

---

**Project**: Agentic Voice-to-Voice Product Discovery  
**Course**: Generative AI, University of Chicago  
**Date**: December 2025
